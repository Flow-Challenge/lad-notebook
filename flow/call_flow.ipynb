{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to execute\n",
    "\n",
    "To execute the application, you need to have a valid flow token. You can obtain this token using one of the following methods:\n",
    "\n",
    "1. Generate a Flow Token Programmatically:\n",
    "    Run the `flow_token.py script`. If the script executes successfully, it will create a `.env` file containing your **FLOW_TENANT** and **FLOW_TOKEN**.\n",
    "\n",
    "\n",
    "\n",
    "2. Retrieve Your Flow Token from Browser Cookies:\n",
    "    Extract your flow token directly from your browser cookies. **Ensure you are logged in with your CI&T account**. For guidance, refer to this [YouTube tutorial](https://youtube.com/clip/Ugkxsv6UO3IpQ2ZLfbb61z4QN90XohMfzh22?si=hYZao7TG1E1SwvSK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "import threading\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowToken = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are some interview questions specifically designed for a Data Scientist position. These questions cover a range of topics, including technical skills, problem-solving abilities, and soft skills.\n",
      "\n",
      "### Technical Questions:\n",
      "\n",
      "1. **Statistical Knowledge**:\n",
      "   - Can you explain the difference between Type I and Type II errors? In what scenarios might each occur?\n",
      "   - What is the central limit theorem, and why is it important in statistics?\n",
      "\n",
      "2. **Machine Learning**:\n",
      "   - Describe the difference between supervised and unsupervised learning. Can you provide examples of each?\n",
      "   - How do you decide which machine learning algorithm to use for a given problem?\n",
      "\n",
      "3. **Data Manipulation and Analysis**:\n",
      "   - Describe your experience with data manipulation tools and libraries (e.g., Pandas, NumPy). Can you give an example of a complex data transformation you performed?\n",
      "   - How do you handle missing data in a dataset?\n",
      "\n",
      "4. **Model Evaluation**:\n",
      "   - What metrics would you use to evaluate the performance of a classification model? How about a regression model?\n",
      "   - Explain the concept of cross-validation and why it is important.\n",
      "\n",
      "5. **Big Data Technologies**:\n",
      "   - What experience do you have with big data technologies like Hadoop, Spark, or distributed databases?\n",
      "   - How would you approach processing a dataset that is too large to fit into memory?\n",
      "\n",
      "### Problem-Solving Questions:\n",
      "\n",
      "6. **Case Studies**:\n",
      "   - Imagine you are given a dataset with customer information and purchase history. How would you approach building a recommendation system?\n",
      "   - Describe a data-driven project you worked on. What was the problem, your approach, and the outcome?\n",
      "\n",
      "7. **Hypothesis Testing**:\n",
      "   - Can you walk us through your process for setting up and testing a hypothesis? What steps do you take to ensure the validity of your results?\n",
      "\n",
      "### Soft Skills and Teamwork:\n",
      "\n",
      "8. **Collaboration**:\n",
      "   - Describe a time when you had to work with a cross-functional team. How did you ensure effective communication and collaboration?\n",
      "   - How do you explain complex technical concepts to non-technical stakeholders?\n",
      "\n",
      "9. **Project Management**:\n",
      "   - How do you prioritize your tasks when working on multiple projects? Can you give an example of a time when you had to manage competing deadlines?\n",
      "   - What tools or methodologies do you use to track your progress on data science projects?\n",
      "\n",
      "### General Questions:\n",
      "\n",
      "10. **Industry Knowledge**:\n",
      "    - How do you stay updated with the latest trends and technologies in data science?\n",
      "    - What are some ethical considerations you take into account when working with data?\n",
      "\n",
      "11. **Personal Experience**:\n",
      "    - What inspired you to become a data scientist, and what do you find most rewarding about the field?\n",
      "    - Can you discuss a challenging data science problem you faced and how you overcame it?\n",
      "\n",
      "These questions can help assess a candidate's technical expertise, problem-solving skills, and ability to communicate effectively within a team.\n"
     ]
    }
   ],
   "source": [
    "#  model_engine = 'gemini-pro'\n",
    "def chatCompletion_v1(prompt, model_engine='gpt-4o'):\n",
    "\n",
    "    flow_llm_url = \"https://flow.ciandt.com/ai-orchestration-api/v1/openai/chat/completions\"\n",
    "    flow_tenant = os.getenv(\"FLOW_TENANT\") or \"lithiadw\"\n",
    "    flow_tenant = os.getenv(\"FLOW_TENANT\") or \"lithiadw\"\n",
    "    \n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"stream\": False,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.7,\n",
    "        \"allowedModels\": [\n",
    "            \"gpt-4o-mini\"\n",
    "        ],\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "    })\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': '*/*',\n",
    "        'FlowTenant': flow_tenant,\n",
    "        'FlowAgent': \"Kanjih-Tools\",\n",
    "        'Authorization': f\"Bearer {flow_token}\",\n",
    "    }\n",
    "\n",
    "    r =  requests.request(\"POST\", flow_llm_url, headers=headers, data=payload)\n",
    "    \n",
    "    if(r.status_code != 200):\n",
    "        print(f\"{r.text} please recreate your flow token\")\n",
    "        return None\n",
    "    \n",
    "    return r.json()['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "\n",
    " # Prompt message\n",
    "message = \"Please generate question for a interview of a Data Scientist\"    \n",
    "response = chatCompletion_v1(message)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lad-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
