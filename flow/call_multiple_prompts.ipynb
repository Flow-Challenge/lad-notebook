{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to execute\n",
    "\n",
    "To execute the application, you need to have a valid flow token. You can obtain this token using one of the following methods:\n",
    "\n",
    "1. Generate a Flow Token Programmatically:\n",
    "    Run the `flow_token.py script`. If the script executes successfully, it will create a `.env` file containing your **FLOW_TENANT** and **FLOW_TOKEN**.\n",
    "\n",
    "\n",
    "\n",
    "2. Retrieve Your Flow Token from Browser Cookies:\n",
    "    Extract your flow token directly from your browser cookies. **Ensure you are logged in with your CI&T account**. For guidance, refer to this [YouTube tutorial](https://youtube.com/clip/Ugkxsv6UO3IpQ2ZLfbb61z4QN90XohMfzh22?si=hYZao7TG1E1SwvSK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "import threading\n",
    "import os\n",
    "import queue\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowToken = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model_engine = 'gemini-pro'\n",
    "def chatCompletion_v1(prompt, output_queue):\n",
    "\n",
    "    flow_llm_url = \"https://flow.ciandt.com/ai-orchestration-api/v1/openai/chat/completions\"\n",
    "    flow_tenant = os.getenv(\"FLOW_TENANT\") or \"lithiadw\"\n",
    "    flow_token = os.getenv(\"FLOW_TOKEN\") or flowToken\n",
    "\n",
    "    if not flow_token:\n",
    "        print(\"Flow token is missing. Please ensure FLOW_TOKEN environment variable is set.\")\n",
    "        return None\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"stream\": False,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.7,\n",
    "        \"allowedModels\": [\n",
    "            \"gpt-4o-mini\"\n",
    "        ],\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \n",
    "    })\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': '*/*',\n",
    "        'FlowTenant': flow_tenant,\n",
    "        'FlowAgent': \"Kanjih-Tools\",\n",
    "        'Authorization': f\"Bearer {flow_token}\",\n",
    "    }\n",
    "\n",
    "    print(f\"\"\"Requesting completion for: {prompt}\"\"\")\n",
    "\n",
    "    r =  requests.request(\"POST\", flow_llm_url, headers=headers, data=payload)\n",
    "    print(f\"Response: {r.status_code}\")\n",
    "    \n",
    "    if(r.status_code != 200):\n",
    "        print(f\"{r.text} please recreate your flow token\")\n",
    "        return None\n",
    "    \n",
    "    # Create a queue to collect results\n",
    "    result = {\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": r.json()['choices'][0]['message']['content']\n",
    "    }\n",
    "    output_queue.put(result)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptsMessages = [\n",
    "    \"Define User Stories: What are the key user stories for this sprint?\",\n",
    "    \"Identify Stakeholders: Who are the stakeholders involved in this project?\",\n",
    "    \"Set Sprint Goals: What are the primary goals we want to achieve in this sprint?\",\n",
    "    \"Create a Product Backlog: What features or tasks should be prioritized in our product backlog?\",\n",
    "    \"Yesterday’s Progress: What did you accomplish yesterday?\",\n",
    "    \"Today’s Focus: What will you be working on today?\",\n",
    "    \"Identify Blockers: Are there any obstacles preventing you from completing your tasks?\",\n",
    "    \"Task Estimation: How long do you estimate each task will take?\",\n",
    "    \"Assign Tasks: Who will be responsible for each task in this sprint?\",\n",
    "    \"Risk Assessment: What potential risks should we be aware of for this sprint?\",\n",
    "    \"Feedback Loop: What feedback do you have for team members on their current tasks?\",\n",
    "    \"Cross-Functional Collaboration: How can we better collaborate with other teams?\",\n",
    "    \"Share Resources: What resources or tools do we need to improve our workflow?\",\n",
    "    \"Update Task Status: What is the current status of your tasks? (To Do, In Progress, Done)\",\n",
    "    \"Review Burndown Chart: How are we tracking against our sprint goals?\",\n",
    "    \"Celebrate Wins: What successes have we achieved this sprint?\",\n",
    "    \"What Went Well: What aspects of the sprint went well?\",\n",
    "    \"Areas for Improvement: What could we improve for the next sprint?\",\n",
    "    \"Action Items: What specific actions can we take to enhance our processes?\",\n",
    "    \"Team Morale: How is everyone feeling about the current workload?\",\n",
    "    \"Skill Development: What skills would you like to develop to contribute more effectively to the project?\",\n",
    "    \"Conflict Resolution: Are there any conflicts within the team that need to be addressed?\",\n",
    "    \"Process Review: Are there any processes we should consider changing?\",\n",
    "    \"Innovation Ideas: What new ideas can we implement to enhance our product?\",\n",
    "    \"Customer Feedback: How can we incorporate customer feedback into our next sprint?\",\n",
    "    \"Long-Term Vision: What is our long-term vision for this project?\",\n",
    "    \"Feature Prioritization: Which features should we focus on in the next few sprints?\",\n",
    "    \"Budget Considerations: Are there any budget constraints we need to consider moving forward?\",\n",
    "    \"Team Building: What team-building activities would you like to engage in?\",\n",
    "    \"Recognition: Who would you like to recognize for their contributions this sprint?\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Number of threads to create\n",
    "num_threads = len(promptsMessages)\n",
    "# Create a queue to collect results\n",
    "output_queue = queue.Queue()\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    # Create a thread, passing i+1 as the argument for print_numbers\n",
    "    thread = threading.Thread(target=chatCompletion_v1, args=(promptsMessages[i], output_queue))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "results = []\n",
    "# Get all results from the queue\n",
    "while not output_queue.empty():\n",
    "    result = output_queue.get()\n",
    "    results.append(result)\n",
    "\n",
    "print(f\"Results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lad-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
